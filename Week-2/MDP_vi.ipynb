{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bfOVILgtJmI5"
   },
   "source": [
    "### Markov decision process\n",
    "\n",
    "This week's methods are all built to solve __M__arkov __D__ecision __P__rocesses. In the broadest sense, an MDP is defined by how it changes states and how rewards are computed.\n",
    "\n",
    "State transition is defined by $P(s' |s,a)$ - how likely are you to end at state $s'$ if you take action $a$ from state $s$. Now there's more than one way to define rewards, but we'll use $r(s,a,s')$ function for convenience.\n",
    "\n",
    "_This notebook is inspired by the awesome_ [CS294](https://github.com/berkeleydeeprlcourse/homework/blob/36a0b58261acde756abd55306fbe63df226bf62b/hw2/HW2.ipynb) _by Berkeley_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tto5qxbmJmI7"
   },
   "source": [
    "For starters, let's define a simple MDP from this picture:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/a/ad/Markov_Decision_Process.svg\" width=\"400px\" alt=\"Diagram by Waldoalvarez via Wikimedia Commons, CC BY-SA 4.0\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "81D-zEbUJmJD"
   },
   "outputs": [],
   "source": [
    "transition_probs = {\n",
    "    's0': {\n",
    "        'a0': {'s0': 0.5, 's2': 0.5},\n",
    "        'a1': {'s2': 1}\n",
    "    },\n",
    "    's1': {\n",
    "        'a0': {'s0': 0.7, 's1': 0.1, 's2': 0.2},\n",
    "        'a1': {'s1': 0.95, 's2': 0.05}\n",
    "    },\n",
    "    's2': {\n",
    "        'a0': {'s0': 0.4, 's2': 0.6},\n",
    "        'a1': {'s0': 0.3, 's1': 0.3, 's2': 0.4}\n",
    "    }\n",
    "}\n",
    "rewards = {\n",
    "    's1': {'a0': {'s0': +5}},\n",
    "    's2': {'a1': {'s0': -1}}\n",
    "}\n",
    "\n",
    "from mdp import MDP\n",
    "mdp = MDP(transition_probs, rewards, initial_state='s0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FTntQOJ0JmJH"
   },
   "source": [
    "We can now use MDP just as any other gym environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "8Fa211p-JmJH",
    "outputId": "0f49438c-3090-44c8-e908-6ab961d55c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state = s0\n",
      "next_state = s2, reward = 0.0, done = False\n"
     ]
    }
   ],
   "source": [
    "print('initial state =', mdp.reset())\n",
    "next_state, reward, done, info = mdp.step('a1')\n",
    "print('next_state = %s, reward = %s, done = %s' % (next_state, reward, done))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cqJ3MkNiJmJO"
   },
   "source": [
    "but it also has other methods that you'll need for Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "OeB37notJmJP",
    "outputId": "0a7a37d0-4193-42f9-94cc-5e21726abc15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdp.get_all_states = ('s0', 's1', 's2')\n",
      "mdp.get_possible_actions('s1') =  ('a0', 'a1')\n",
      "mdp.get_next_states('s1', 'a0') =  {'s0': 0.7, 's1': 0.1, 's2': 0.2}\n",
      "mdp.get_reward('s1', 'a0', 's0') =  5\n",
      "mdp.get_transition_prob('s1', 'a0', 's0') =  0.7\n"
     ]
    }
   ],
   "source": [
    "print(\"mdp.get_all_states =\", mdp.get_all_states())\n",
    "print(\"mdp.get_possible_actions('s1') = \", mdp.get_possible_actions('s1'))\n",
    "print(\"mdp.get_next_states('s1', 'a0') = \", mdp.get_next_states('s1', 'a0'))\n",
    "print(\"mdp.get_reward('s1', 'a0', 's0') = \", mdp.get_reward('s1', 'a0', 's0'))\n",
    "print(\"mdp.get_transition_prob('s1', 'a0', 's0') = \",\n",
    "      mdp.get_transition_prob('s1', 'a0', 's0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aR5eb5tFJmJZ"
   },
   "source": [
    "### Value Iteration\n",
    "\n",
    "Now let's build something to solve this MDP. The simplest algorithm so far is __V__alue __I__teration\n",
    "\n",
    "### Value Iteration in Words:\n",
    "For a single state, value function is given by:\n",
    "$ \\quad V_{(i+1)}(s) = \\max_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')]$, for all $s$\n",
    "\n",
    "The new value function is the probability of landing in s' from 's' after picking action 'a' multiplied by expected immediate reward obtained + value function of the next state s'. Here action 'a' is considered to be the best action i.e which maximizes the value of the state\n",
    "\n",
    "Here's the pseudo-code for VI:\n",
    "\n",
    "---\n",
    "\n",
    "`1.` Initialize $V^{(0)}(s)=0$, for all $s$\n",
    "\n",
    "`2.` For $i=0, 1, 2, \\dots$\n",
    " \n",
    "`3.` $ \\quad V_{(i+1)}(s) = \\max_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')]$, for all $s$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Kx2f2WdJmJZ"
   },
   "source": [
    "In order to calculate V(s), we need to find the best action that leads to maximum V(s). Best action is obtained by computing the state-action value function $Q^{\\pi}$, defined as follows\n",
    "\n",
    "$$Q_i(s, a) = \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')]$$\n",
    "$Q_i(s, a)$ gives us the value of a state after picking an action 'a'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c0-y-Vs6JmJZ",
    "outputId": "6fc0de31-faed-407d-c812-f7eb3d72e8e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mdp_get_action_value.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mdp_get_action_value.py\n",
    "\n",
    "def get_action_value(mdp, state_values, state, action, gamma):\n",
    "    \"\"\" Computes Q(s,a) as in formula above \"\"\"\n",
    "    Q=0\n",
    "    next_states = mdp.get_next_states(state, action)\n",
    "    for next_state in next_states:\n",
    "      probability = next_states[next_state]\n",
    "      reward = mdp.get_reward(state,action,next_state)\n",
    "      Q += probability*(reward + gamma*state_values[next_state])\n",
    "    \n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oMgUgVaFJmJc"
   },
   "outputs": [],
   "source": [
    "from mdp_get_action_value import get_action_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1jyYZYTJmJe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_Vs = {s: i for i, s in enumerate(sorted(mdp.get_all_states()))}\n",
    "assert np.isclose(get_action_value(mdp, test_Vs, 's2', 'a1', 0.9), 0.69)\n",
    "assert np.isclose(get_action_value(mdp, test_Vs, 's1', 'a0', 0.9), 3.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70t1ZRUlJmJg"
   },
   "source": [
    "V(s) is nothing but the max Q(s,a). max Q(s,a) is the value of the state obtained by picking the best action. \n",
    "\n",
    "Using $Q(s,a)$ we can now define the \"next\" V(s) for value iteration.\n",
    " $$V_{(i+1)}(s) = \\max_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')] = \\max_a Q_i(s,a)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRvQN_ydJmJh"
   },
   "outputs": [],
   "source": [
    "def get_new_state_value(mdp, state_values, state, gamma):\n",
    "    \"\"\" Computes next V(s) as in formula above. Please do not change state_values in process. \"\"\"\n",
    "    if mdp.is_terminal(state):\n",
    "        return 0\n",
    "    actions = mdp.get_possible_actions(state)\n",
    "    state_value = 0\n",
    "    for action in actions:\n",
    "      action_value = get_action_value(mdp, state_values,state,action,gamma)\n",
    "      if(action_value>state_value):\n",
    "        state_value = action_value\n",
    "\n",
    "\n",
    "    # <YOUR CODE>\n",
    "    return state_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DrRn3Lv1JmJj"
   },
   "outputs": [],
   "source": [
    "test_Vs_copy = dict(test_Vs)\n",
    "assert np.isclose(get_new_state_value(mdp, test_Vs, 's0', 0.9), 1.8)\n",
    "assert np.isclose(get_new_state_value(mdp, test_Vs, 's2', 0.9), 1.08)\n",
    "assert test_Vs == test_Vs_copy, \"please do not change state_values in get_new_state_value\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxZT9p0RJmJm"
   },
   "source": [
    "Finally, let's combine everything we wrote into a working value iteration algo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6HO3-y5iJmJm",
    "outputId": "fb5569e1-38bc-4eb3-e33b-2d91fa31d1aa"
   },
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m         \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstartupinfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_startupinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    774\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    776\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1179\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\graphviz\\files.py\u001b[0m in \u001b[0;36m_repr_svg_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_svg_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\graphviz\\files.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(self, format, renderer, formatter, quiet)\u001b[0m\n\u001b[0;32m    136\u001b[0m         out = backend.pipe(self._engine, format, data,\n\u001b[0;32m    137\u001b[0m                            \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                            quiet=quiet)\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(engine, format, data, renderer, formatter, quiet)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \"\"\"\n\u001b[0;32m    228\u001b[0m     \u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcommand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m     \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.dot.Digraph at 0x234977aadc8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 3.50000   |   V(s0) = 0.000   V(s1) = 0.000   V(s2) = 0.000\n",
      "\n",
      "iter    1   |   diff: 0.64500   |   V(s0) = 0.000   V(s1) = 3.500   V(s2) = 0.000\n",
      "\n",
      "iter    2   |   diff: 0.58050   |   V(s0) = 0.000   V(s1) = 3.815   V(s2) = 0.645\n",
      "\n",
      "iter    3   |   diff: 0.43582   |   V(s0) = 0.581   V(s1) = 3.959   V(s2) = 0.962\n",
      "\n",
      "iter    4   |   diff: 0.30634   |   V(s0) = 0.866   V(s1) = 4.395   V(s2) = 1.272\n",
      "\n",
      "iter    5   |   diff: 0.27571   |   V(s0) = 1.145   V(s1) = 4.670   V(s2) = 1.579\n",
      "\n",
      "iter    6   |   diff: 0.24347   |   V(s0) = 1.421   V(s1) = 4.926   V(s2) = 1.838\n",
      "\n",
      "iter    7   |   diff: 0.21419   |   V(s0) = 1.655   V(s1) = 5.169   V(s2) = 2.075\n",
      "\n",
      "iter    8   |   diff: 0.19277   |   V(s0) = 1.868   V(s1) = 5.381   V(s2) = 2.290\n",
      "\n",
      "iter    9   |   diff: 0.17327   |   V(s0) = 2.061   V(s1) = 5.573   V(s2) = 2.481\n",
      "\n",
      "iter   10   |   diff: 0.15569   |   V(s0) = 2.233   V(s1) = 5.746   V(s2) = 2.654\n",
      "\n",
      "iter   11   |   diff: 0.14012   |   V(s0) = 2.389   V(s1) = 5.902   V(s2) = 2.810\n",
      "\n",
      "iter   12   |   diff: 0.12610   |   V(s0) = 2.529   V(s1) = 6.042   V(s2) = 2.950\n",
      "\n",
      "iter   13   |   diff: 0.11348   |   V(s0) = 2.655   V(s1) = 6.168   V(s2) = 3.076\n",
      "\n",
      "iter   14   |   diff: 0.10213   |   V(s0) = 2.769   V(s1) = 6.282   V(s2) = 3.190\n",
      "\n",
      "iter   15   |   diff: 0.09192   |   V(s0) = 2.871   V(s1) = 6.384   V(s2) = 3.292\n",
      "\n",
      "iter   16   |   diff: 0.08272   |   V(s0) = 2.963   V(s1) = 6.476   V(s2) = 3.384\n",
      "\n",
      "iter   17   |   diff: 0.07445   |   V(s0) = 3.045   V(s1) = 6.558   V(s2) = 3.467\n",
      "\n",
      "iter   18   |   diff: 0.06701   |   V(s0) = 3.120   V(s1) = 6.633   V(s2) = 3.541\n",
      "\n",
      "iter   19   |   diff: 0.06031   |   V(s0) = 3.187   V(s1) = 6.700   V(s2) = 3.608\n",
      "\n",
      "iter   20   |   diff: 0.05428   |   V(s0) = 3.247   V(s1) = 6.760   V(s2) = 3.668\n",
      "\n",
      "iter   21   |   diff: 0.04885   |   V(s0) = 3.301   V(s1) = 6.814   V(s2) = 3.723\n",
      "\n",
      "iter   22   |   diff: 0.04396   |   V(s0) = 3.350   V(s1) = 6.863   V(s2) = 3.771\n",
      "\n",
      "iter   23   |   diff: 0.03957   |   V(s0) = 3.394   V(s1) = 6.907   V(s2) = 3.815\n",
      "\n",
      "iter   24   |   diff: 0.03561   |   V(s0) = 3.434   V(s1) = 6.947   V(s2) = 3.855\n",
      "\n",
      "iter   25   |   diff: 0.03205   |   V(s0) = 3.469   V(s1) = 6.982   V(s2) = 3.891\n",
      "\n",
      "iter   26   |   diff: 0.02884   |   V(s0) = 3.502   V(s1) = 7.014   V(s2) = 3.923\n",
      "\n",
      "iter   27   |   diff: 0.02596   |   V(s0) = 3.530   V(s1) = 7.043   V(s2) = 3.951\n",
      "\n",
      "iter   28   |   diff: 0.02336   |   V(s0) = 3.556   V(s1) = 7.069   V(s2) = 3.977\n",
      "\n",
      "iter   29   |   diff: 0.02103   |   V(s0) = 3.580   V(s1) = 7.093   V(s2) = 4.001\n",
      "\n",
      "iter   30   |   diff: 0.01892   |   V(s0) = 3.601   V(s1) = 7.114   V(s2) = 4.022\n",
      "\n",
      "iter   31   |   diff: 0.01703   |   V(s0) = 3.620   V(s1) = 7.133   V(s2) = 4.041\n",
      "\n",
      "iter   32   |   diff: 0.01533   |   V(s0) = 3.637   V(s1) = 7.150   V(s2) = 4.058\n",
      "\n",
      "iter   33   |   diff: 0.01380   |   V(s0) = 3.652   V(s1) = 7.165   V(s2) = 4.073\n",
      "\n",
      "iter   34   |   diff: 0.01242   |   V(s0) = 3.666   V(s1) = 7.179   V(s2) = 4.087\n",
      "\n",
      "iter   35   |   diff: 0.01117   |   V(s0) = 3.678   V(s1) = 7.191   V(s2) = 4.099\n",
      "\n",
      "iter   36   |   diff: 0.01006   |   V(s0) = 3.689   V(s1) = 7.202   V(s2) = 4.110\n",
      "\n",
      "iter   37   |   diff: 0.00905   |   V(s0) = 3.699   V(s1) = 7.212   V(s2) = 4.121\n",
      "\n",
      "iter   38   |   diff: 0.00815   |   V(s0) = 3.708   V(s1) = 7.221   V(s2) = 4.130\n",
      "\n",
      "iter   39   |   diff: 0.00733   |   V(s0) = 3.717   V(s1) = 7.230   V(s2) = 4.138\n",
      "\n",
      "iter   40   |   diff: 0.00660   |   V(s0) = 3.724   V(s1) = 7.237   V(s2) = 4.145\n",
      "\n",
      "iter   41   |   diff: 0.00594   |   V(s0) = 3.731   V(s1) = 7.244   V(s2) = 4.152\n",
      "\n",
      "iter   42   |   diff: 0.00534   |   V(s0) = 3.736   V(s1) = 7.249   V(s2) = 4.158\n",
      "\n",
      "iter   43   |   diff: 0.00481   |   V(s0) = 3.742   V(s1) = 7.255   V(s2) = 4.163\n",
      "\n",
      "iter   44   |   diff: 0.00433   |   V(s0) = 3.747   V(s1) = 7.260   V(s2) = 4.168\n",
      "\n",
      "iter   45   |   diff: 0.00390   |   V(s0) = 3.751   V(s1) = 7.264   V(s2) = 4.172\n",
      "\n",
      "iter   46   |   diff: 0.00351   |   V(s0) = 3.755   V(s1) = 7.268   V(s2) = 4.176\n",
      "\n",
      "iter   47   |   diff: 0.00316   |   V(s0) = 3.758   V(s1) = 7.271   V(s2) = 4.179\n",
      "\n",
      "iter   48   |   diff: 0.00284   |   V(s0) = 3.762   V(s1) = 7.275   V(s2) = 4.183\n",
      "\n",
      "iter   49   |   diff: 0.00256   |   V(s0) = 3.764   V(s1) = 7.277   V(s2) = 4.185\n",
      "\n",
      "iter   50   |   diff: 0.00230   |   V(s0) = 3.767   V(s1) = 7.280   V(s2) = 4.188\n",
      "\n",
      "iter   51   |   diff: 0.00207   |   V(s0) = 3.769   V(s1) = 7.282   V(s2) = 4.190\n",
      "\n",
      "iter   52   |   diff: 0.00186   |   V(s0) = 3.771   V(s1) = 7.284   V(s2) = 4.192\n",
      "\n",
      "iter   53   |   diff: 0.00168   |   V(s0) = 3.773   V(s1) = 7.286   V(s2) = 4.194\n",
      "\n",
      "iter   54   |   diff: 0.00151   |   V(s0) = 3.775   V(s1) = 7.288   V(s2) = 4.196\n",
      "\n",
      "iter   55   |   diff: 0.00136   |   V(s0) = 3.776   V(s1) = 7.289   V(s2) = 4.197\n",
      "\n",
      "iter   56   |   diff: 0.00122   |   V(s0) = 3.778   V(s1) = 7.291   V(s2) = 4.199\n",
      "\n",
      "iter   57   |   diff: 0.00110   |   V(s0) = 3.779   V(s1) = 7.292   V(s2) = 4.200\n",
      "\n",
      "iter   58   |   diff: 0.00099   |   V(s0) = 3.780   V(s1) = 7.293   V(s2) = 4.201\n",
      "\n",
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# parameters\n",
    "gamma = 0.9            # discount for MDP\n",
    "num_iter = 100         # maximum iterations, excluding initialization\n",
    "min_difference = 0.001 # stop VI if new values are this close to old values (or closer)\n",
    "\n",
    "# initialize V(s)\n",
    "state_values = {s : 0 for s in mdp.get_all_states()}\n",
    "\n",
    "if has_graphviz:\n",
    "    display(plot_graph_with_state_values(mdp, state_values))\n",
    "\n",
    "new_state_values = {}\n",
    "\n",
    "for i in range(num_iter):\n",
    "    \n",
    "    # Compute new state values using the functions you defined above. It must be a dict {state : new_V(state)}\n",
    "    for s in state_values:\n",
    "        new_state_values[s] = get_new_state_value(mdp, state_values, s, gamma) #<YOUR CODE>\n",
    "    assert isinstance(new_state_values, dict)\n",
    "    \n",
    "    # Compute difference\n",
    "    #print(new_state_values)\n",
    "    #print(state_values)\n",
    "    diffs = [abs(new_state_values[s] - state_values[s]) for s in mdp.get_all_states()]\n",
    "    #print(diffs)\n",
    "    diff = max(abs(new_state_values[s] - state_values[s]) for s in mdp.get_all_states())\n",
    "    print(\"iter %4i   |   diff: %6.5f   |   \"%(i, diff), end=\"\")\n",
    "    print('   '.join(\"V(%s) = %.3f\"%(s, v) for s,v in state_values.items()), end='\\n\\n')\n",
    "    state_values = dict(new_state_values)\n",
    "    #print(state_values)\n",
    "    \n",
    "    if diff < min_difference:\n",
    "        print(\"Terminated\"); break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QD1PCWGYJmJq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final state values: {'s0': 3.7810348735476405, 's1': 7.294006423867229, 's2': 4.202140275227048}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final state values:\", state_values)\n",
    "\n",
    "assert abs(state_values['s0'] - 3.781) < 0.01\n",
    "assert abs(state_values['s1'] - 7.294) < 0.01\n",
    "assert abs(state_values['s2'] - 4.202) < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oauoqjLnJmJu"
   },
   "source": [
    "Now let's use those $V^{*}(s)$ to find optimal actions in each state\n",
    "\n",
    " $$\\pi^*(s) = argmax_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')] = argmax_a Q_i(s,a)$$\n",
    " \n",
    "The only difference vs V(s) is that here we take not max but argmax: find action such with maximum Q(s,a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMNpQSK5JmJu"
   },
   "outputs": [],
   "source": [
    "def get_optimal_action(mdp, state_values, state, gamma=0.9):\n",
    "    \"\"\" Finds optimal action using formula above. \"\"\"\n",
    "    if mdp.is_terminal(state):\n",
    "        return None\n",
    "    optimal_action = None\n",
    "    optimal_action_value = - float('inf')\n",
    "    actions = mdp.get_possible_actions(state)\n",
    "    for action in actions:\n",
    "        action_value = get_action_value(mdp, state_values, state, action, gamma)\n",
    "        if(action_value > optimal_action_value):\n",
    "            optimal_action_value = action_value\n",
    "            optimal_action = action\n",
    "        \n",
    "\n",
    "    # <YOUR CODE HERE>\n",
    "\n",
    "    return optimal_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OsAgdVnQJmJw"
   },
   "outputs": [],
   "source": [
    "assert get_optimal_action(mdp, state_values, 's0', gamma) == 'a1'\n",
    "assert get_optimal_action(mdp, state_values, 's1', gamma) == 'a0'\n",
    "assert get_optimal_action(mdp, state_values, 's2', gamma) == 'a1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eK6prxH7JmJ0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average reward:  0.4364\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "\n",
    "s = mdp.reset()\n",
    "rewards = []\n",
    "for _ in range(10000):\n",
    "    s, r, done, _ = mdp.step(get_optimal_action(mdp, state_values, s, gamma))\n",
    "    rewards.append(r)\n",
    "\n",
    "print(\"average reward: \", np.mean(rewards))\n",
    "\n",
    "assert(0.40 < np.mean(rewards) < 0.55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7bD_DKGtJmJ2"
   },
   "source": [
    "### Frozen lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wCFki4-mJmJ2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*FFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mdp import FrozenLakeEnv\n",
    "mdp = FrozenLakeEnv(slip_chance=0)\n",
    "\n",
    "mdp.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Optimal Value Function(V*)__: Obtained by _Value Iteration_ i.e generate new state value functions until convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2HVl4XFJmJ4"
   },
   "outputs": [],
   "source": [
    "def value_iteration(mdp, state_values=None, gamma = 0.9, num_iter = 1000, min_difference = 1e-5):\n",
    "    \"\"\" performs num_iter value iteration steps starting from state_values. Same as before but in a function \"\"\"\n",
    "    state_values = state_values or {s : 0 for s in mdp.get_all_states()}\n",
    "    new_state_values = {}\n",
    "    #Generate episodes/\n",
    "    for i in range(num_iter):\n",
    "\n",
    "        # Compute new state values for each state in an episode.\n",
    "        for s in state_values:\n",
    "            new_state_values[s] = get_new_state_value(mdp, state_values, s, gamma)\n",
    "        assert isinstance(new_state_values, dict)\n",
    "\n",
    "        # Compute difference for stopping condition\n",
    "        diff = max(abs(new_state_values[s] - state_values[s]) for s in mdp.get_all_states())\n",
    "        print(\"iter %4i   |   diff: %6.5f   |   V(start): %.3f \"%(i, diff, new_state_values[mdp._initial_state]))\n",
    "        \n",
    "        state_values = dict(new_state_values)\n",
    "        #If difference in state values gets very miniscule terminate, value function has converged\n",
    "        if diff < min_difference:\n",
    "            print(\"Terminated\"); break\n",
    "            \n",
    "    return state_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJyObiysJmJ5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.90000   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.81000   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.72900   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.65610   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.59049   |   V(start): 0.590 \n",
      "iter    6   |   diff: 0.00000   |   V(start): 0.590 \n",
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "state_values = value_iteration(mdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Optimal Policy__: Once we know V*(optimal state values), we can find optimal policy by choosing the best action at every time step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kJvamltQJmJ7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*FFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "down\n",
      "\n",
      "SFFF\n",
      "*HFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "down\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "*FFH\n",
      "HFFG\n",
      "\n",
      "right\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "F*FH\n",
      "HFFG\n",
      "\n",
      "down\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H*FG\n",
      "\n",
      "right\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF*G\n",
      "\n",
      "right\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = mdp.reset()\n",
    "mdp.render()\n",
    "for t in range(100):\n",
    "    a = get_optimal_action(mdp, state_values, s, gamma)\n",
    "    print(a, end='\\n\\n')\n",
    "    s, r, done, _ = mdp.step(a)\n",
    "    mdp.render()\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7eT645sOJmJ9"
   },
   "source": [
    "### Let's visualize!\n",
    "\n",
    "It's usually interesting to see what your algorithm actually learned under the hood. To do so, we'll plot state value functions and optimal actions at each VI step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gXTYED2IJmJ9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def draw_policy(mdp, state_values):\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    h, w = mdp.desc.shape\n",
    "    states = sorted(mdp.get_all_states())\n",
    "    V = np.array([state_values[s] for s in states])\n",
    "    Pi = {s: get_optimal_action(mdp, state_values, s, gamma) for s in states}\n",
    "    plt.imshow(V.reshape(w, h), cmap='gray', interpolation='none', clim=(0, 1))\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(np.arange(h)-.5)\n",
    "    ax.set_yticks(np.arange(w)-.5)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    Y, X = np.mgrid[0:4, 0:4]\n",
    "    a2uv = {'left': (-1, 0), 'down': (0, -1), 'right': (1, 0), 'up': (0, 1)}\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            plt.text(x, y, str(mdp.desc[y, x].item()),\n",
    "                     color='g', size=12,  verticalalignment='center',\n",
    "                     horizontalalignment='center', fontweight='bold')\n",
    "            a = Pi[y, x]\n",
    "            if a is None:\n",
    "                continue\n",
    "            u, v = a2uv[a]\n",
    "            plt.arrow(x, y, u*.3, -v*.3, color='m',\n",
    "                      head_width=0.1, head_length=0.1)\n",
    "    plt.grid(color='b', lw=2, ls='-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSk854vpJmKA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 0\n",
      "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 1\n",
      "iter    0   |   diff: 0.90000   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 2\n",
      "iter    0   |   diff: 0.81000   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 3\n",
      "iter    0   |   diff: 0.72900   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 4\n",
      "iter    0   |   diff: 0.65610   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 5\n",
      "iter    0   |   diff: 0.59049   |   V(start): 0.590 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 6\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n",
      "Terminated\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 7\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n",
      "Terminated\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 8\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n",
      "Terminated\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 9\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n",
      "Terminated\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_values = {s: 0 for s in mdp.get_all_states()}\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"after iteration %i\" % i)\n",
    "    state_values = value_iteration(mdp, state_values, num_iter=1)\n",
    "    draw_policy(mdp, state_values)\n",
    "# please ignore iter 0 at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6knLoBxTJmKB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 29\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.198 \n",
      "Terminated\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "mdp = FrozenLakeEnv(map_name='8x8', slip_chance=0.1)\n",
    "state_values = {s: 0 for s in mdp.get_all_states()}\n",
    "\n",
    "for i in range(30):\n",
    "    clear_output(True)\n",
    "    print(\"after iteration %i\" % i)\n",
    "    state_values = value_iteration(mdp, state_values, num_iter=1)\n",
    "    draw_policy(mdp, state_values)\n",
    "    sleep(0.5)\n",
    "# please ignore iter 0 at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-FdtziW9JmKD"
   },
   "source": [
    "Massive tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8_6eu0EvJmKD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.90000   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.81000   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.72900   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.65610   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.59049   |   V(start): 0.590 \n",
      "iter    6   |   diff: 0.00000   |   V(start): 0.590 \n",
      "Terminated\n",
      "average reward:  1.0\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "mdp = FrozenLakeEnv(slip_chance=0)\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(\n",
    "            get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "\n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(1.0 <= np.mean(total_rewards) <= 1.0)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ay-bObxgJmKF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 0.90000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.72900   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.62330   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.50487   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.40894   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.34868   |   V(start): 0.349 \n",
      "iter    6   |   diff: 0.06529   |   V(start): 0.410 \n",
      "iter    7   |   diff: 0.05832   |   V(start): 0.468 \n",
      "iter    8   |   diff: 0.01139   |   V(start): 0.480 \n",
      "iter    9   |   diff: 0.00764   |   V(start): 0.487 \n",
      "iter   10   |   diff: 0.00164   |   V(start): 0.489 \n",
      "iter   11   |   diff: 0.00094   |   V(start): 0.490 \n",
      "iter   12   |   diff: 0.00022   |   V(start): 0.490 \n",
      "iter   13   |   diff: 0.00011   |   V(start): 0.490 \n",
      "iter   14   |   diff: 0.00003   |   V(start): 0.490 \n",
      "iter   15   |   diff: 0.00001   |   V(start): 0.490 \n",
      "iter   16   |   diff: 0.00000   |   V(start): 0.490 \n",
      "Terminated\n",
      "average reward:  0.883\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "mdp = FrozenLakeEnv(slip_chance=0.1)\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(\n",
    "            get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "\n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(0.8 <= np.mean(total_rewards) <= 0.95)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDiizNx2JmKH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 0.75000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.50625   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.39867   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.26910   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.18164   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.14013   |   V(start): 0.140 \n",
      "iter    6   |   diff: 0.07028   |   V(start): 0.199 \n",
      "iter    7   |   diff: 0.06030   |   V(start): 0.260 \n",
      "iter    8   |   diff: 0.02594   |   V(start): 0.285 \n",
      "iter    9   |   diff: 0.01918   |   V(start): 0.305 \n",
      "iter   10   |   diff: 0.00858   |   V(start): 0.313 \n",
      "iter   11   |   diff: 0.00560   |   V(start): 0.319 \n",
      "iter   12   |   diff: 0.00260   |   V(start): 0.321 \n",
      "iter   13   |   diff: 0.00159   |   V(start): 0.323 \n",
      "iter   14   |   diff: 0.00076   |   V(start): 0.324 \n",
      "iter   15   |   diff: 0.00045   |   V(start): 0.324 \n",
      "iter   16   |   diff: 0.00022   |   V(start): 0.324 \n",
      "iter   17   |   diff: 0.00012   |   V(start): 0.325 \n",
      "iter   18   |   diff: 0.00006   |   V(start): 0.325 \n",
      "iter   19   |   diff: 0.00003   |   V(start): 0.325 \n",
      "iter   20   |   diff: 0.00002   |   V(start): 0.325 \n",
      "iter   21   |   diff: 0.00001   |   V(start): 0.325 \n",
      "Terminated\n",
      "average reward:  0.657\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "mdp = FrozenLakeEnv(slip_chance=0.25)\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(\n",
    "            get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "\n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(0.6 <= np.mean(total_rewards) <= 0.7)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oSTSXM_oJmKJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 0.80000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.57600   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.41472   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.29860   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.24186   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.19349   |   V(start): 0.000 \n",
      "iter    6   |   diff: 0.15325   |   V(start): 0.000 \n",
      "iter    7   |   diff: 0.12288   |   V(start): 0.000 \n",
      "iter    8   |   diff: 0.09930   |   V(start): 0.000 \n",
      "iter    9   |   diff: 0.08037   |   V(start): 0.000 \n",
      "iter   10   |   diff: 0.06426   |   V(start): 0.000 \n",
      "iter   11   |   diff: 0.05129   |   V(start): 0.000 \n",
      "iter   12   |   diff: 0.04330   |   V(start): 0.000 \n",
      "iter   13   |   diff: 0.03802   |   V(start): 0.033 \n",
      "iter   14   |   diff: 0.03332   |   V(start): 0.058 \n",
      "iter   15   |   diff: 0.02910   |   V(start): 0.087 \n",
      "iter   16   |   diff: 0.01855   |   V(start): 0.106 \n",
      "iter   17   |   diff: 0.01403   |   V(start): 0.120 \n",
      "iter   18   |   diff: 0.00810   |   V(start): 0.128 \n",
      "iter   19   |   diff: 0.00555   |   V(start): 0.133 \n",
      "iter   20   |   diff: 0.00321   |   V(start): 0.137 \n",
      "iter   21   |   diff: 0.00247   |   V(start): 0.138 \n",
      "iter   22   |   diff: 0.00147   |   V(start): 0.139 \n",
      "iter   23   |   diff: 0.00104   |   V(start): 0.140 \n",
      "iter   24   |   diff: 0.00058   |   V(start): 0.140 \n",
      "iter   25   |   diff: 0.00036   |   V(start): 0.141 \n",
      "iter   26   |   diff: 0.00024   |   V(start): 0.141 \n",
      "iter   27   |   diff: 0.00018   |   V(start): 0.141 \n",
      "iter   28   |   diff: 0.00012   |   V(start): 0.141 \n",
      "iter   29   |   diff: 0.00007   |   V(start): 0.141 \n",
      "iter   30   |   diff: 0.00004   |   V(start): 0.141 \n",
      "iter   31   |   diff: 0.00003   |   V(start): 0.141 \n",
      "iter   32   |   diff: 0.00001   |   V(start): 0.141 \n",
      "iter   33   |   diff: 0.00001   |   V(start): 0.141 \n",
      "Terminated\n",
      "average reward:  0.756\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "mdp = FrozenLakeEnv(slip_chance=0.2, map_name='8x8')\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(\n",
    "            get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "\n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(0.6 <= np.mean(total_rewards) <= 0.8)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4hILWyPwJmKL"
   },
   "source": [
    "# HW Part 1: Value iteration convergence\n",
    "\n",
    "### Find an MDP for which value iteration takes long to converge  (0.5 pts)\n",
    "\n",
    "When we ran value iteration on the small frozen lake problem, the last iteration where an action changed was iteration 6--i.e., value iteration computed the optimal policy at iteration 6. Are there any guarantees regarding how many iterations it'll take value iteration to compute the optimal policy? There are no such guarantees without additional assumptions--we can construct the MDP in such a way that the greedy policy will change after arbitrarily many iterations.\n",
    "\n",
    "Your task: define an MDP with at most 3 states and 2 actions, such that when you run value iteration, the optimal action changes at iteration >= 50. Use discount=0.95. (However, note that the discount doesn't matter here--you can construct an appropriate MDP with any discount.)\n",
    "\n",
    "Note: value function must change at least once after iteration >=50, not necessarily change on every iteration till >=50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "axPqltqZJmKL"
   },
   "outputs": [],
   "source": [
    "transition_probs = {\n",
    "    < YOUR CODE >\n",
    "}\n",
    "rewards = {\n",
    "    < YOUR CODE >\n",
    "}\n",
    "\n",
    "from mdp import MDP\n",
    "from numpy import random\n",
    "mdp = MDP(transition_probs, rewards, initial_state=random.choice(tuple(transition_probs.keys())))\n",
    "# Feel free to change the initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9GcHGpUzJmKN"
   },
   "outputs": [],
   "source": [
    "state_values = {s: 0 for s in mdp.get_all_states()}\n",
    "policy = np.array([get_optimal_action(mdp, state_values, state, gamma)\n",
    "                   for state in sorted(mdp.get_all_states())])\n",
    "\n",
    "for i in range(100):\n",
    "    print(\"after iteration %i\" % i)\n",
    "    state_values = value_iteration(mdp, state_values, num_iter=1)\n",
    "\n",
    "    new_policy = np.array([get_optimal_action(mdp, state_values, state, gamma)\n",
    "                           for state in sorted(mdp.get_all_states())])\n",
    "\n",
    "    n_changes = (policy != new_policy).sum()\n",
    "    print(\"N actions changed = %i \\n\" % n_changes)\n",
    "    policy = new_policy\n",
    "\n",
    "# please ignore iter 0 at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oQPIpNSfJmKQ"
   },
   "source": [
    "### Value iteration convervence proof (0.5 pts)\n",
    "**Note:** Assume that $\\mathcal{S}, \\mathcal{A}$ are finite.\n",
    "\n",
    "Update of value function in value iteration can be rewritten in a form of Bellman operator:\n",
    "\n",
    "$$(TV)(s) = \\max_{a \\in \\mathcal{A}}\\mathbb{E}\\left[ r_{t+1} + \\gamma V(s_{t+1}) | s_t = s, a_t = a\\right]$$\n",
    "\n",
    "Value iteration algorithm with Bellman operator:\n",
    "\n",
    "---\n",
    "&nbsp;&nbsp; Initialize $V_0$\n",
    "\n",
    "&nbsp;&nbsp; **for** $k = 0,1,2,...$ **do**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $V_{k+1} \\leftarrow TV_k$\n",
    "\n",
    "&nbsp;&nbsp;**end for**\n",
    "\n",
    "---\n",
    "\n",
    "In [lecture](https://docs.google.com/presentation/d/1lz2oIUTvd2MHWKEQSH8hquS66oe4MZ_eRvVViZs2uuE/edit#slide=id.g4fd6bae29e_2_4) we established contraction property of bellman operator:\n",
    "\n",
    "$$\n",
    "||TV - TU||_{\\infty} \\le \\gamma ||V - U||_{\\infty}\n",
    "$$\n",
    "\n",
    "For all $V, U$\n",
    "\n",
    "Using contraction property of Bellman operator, Banach fixed-point theorem and Bellman equations prove that value function converges to $V^*$ in value iterateion$\n",
    "\n",
    "*<-- Your proof here -->*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SHvjT4YNJmKR"
   },
   "source": [
    "### Bonus. Asynchronious value iteration (2 pts)\n",
    "\n",
    "Consider the following algorithm:\n",
    "\n",
    "---\n",
    "\n",
    "Initialize $V_0$\n",
    "\n",
    "**for** $k = 0,1,2,...$ **do**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Select some state $s_k \\in \\mathcal{S}$    \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $V(s_k) := (TV)(s_k)$\n",
    "\n",
    "**end for**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Note that unlike common value iteration, here we update only a single state at a time.\n",
    "\n",
    "**Homework.** Prove the following proposition:\n",
    "\n",
    "If for all $s \\in \\mathcal{S}$, $s$ appears in the sequence $(s_0, s_1, ...)$ infinitely often, then $V$ converges to $V*$\n",
    "\n",
    "*<-- Your proof here -->*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pTuLZ0wlJmKR"
   },
   "source": [
    "# HW Part 2: Policy iteration\n",
    "\n",
    "## Policy iteration implementateion (2 pts)\n",
    "\n",
    "Let's implement exact policy iteration (PI), which has the following pseudocode:\n",
    "\n",
    "---\n",
    "Initialize $\\pi_0$   `// random or fixed action`\n",
    "\n",
    "For $n=0, 1, 2, \\dots$\n",
    "- Compute the state-value function $V^{\\pi_{n}}$\n",
    "- Using $V^{\\pi_{n}}$, compute the state-action-value function $Q^{\\pi_{n}}$\n",
    "- Compute new policy $\\pi_{n+1}(s) = \\operatorname*{argmax}_a Q^{\\pi_{n}}(s,a)$\n",
    "---\n",
    "\n",
    "Unlike VI, policy iteration has to maintain a policy - chosen actions from all states - and estimate $V^{\\pi_{n}}$ based on this policy. It only changes policy once values converged.\n",
    "\n",
    "\n",
    "Below are a few helpers that you may or may not use in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6O4xPi_JmKR"
   },
   "outputs": [],
   "source": [
    "transition_probs = {\n",
    "    's0': {\n",
    "        'a0': {'s0': 0.5, 's2': 0.5},\n",
    "        'a1': {'s2': 1}\n",
    "    },\n",
    "    's1': {\n",
    "        'a0': {'s0': 0.7, 's1': 0.1, 's2': 0.2},\n",
    "        'a1': {'s1': 0.95, 's2': 0.05}\n",
    "    },\n",
    "    's2': {\n",
    "        'a0': {'s0': 0.4, 's1': 0.6},\n",
    "        'a1': {'s0': 0.3, 's1': 0.3, 's2': 0.4}\n",
    "    }\n",
    "}\n",
    "rewards = {\n",
    "    's1': {'a0': {'s0': +5}},\n",
    "    's2': {'a1': {'s0': -1}}\n",
    "}\n",
    "\n",
    "from mdp import MDP\n",
    "mdp = MDP(transition_probs, rewards, initial_state='s0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WMoM1OfSJmKT"
   },
   "source": [
    "Let's write a function called `compute_vpi` that computes the state-value function $V^{\\pi}$ for an arbitrary policy $\\pi$.\n",
    "\n",
    "Unlike VI, this time you must find the exact solution, not just a single iteration.\n",
    "\n",
    "Recall that $V^{\\pi}$ satisfies the following linear equation:\n",
    "$$V^{\\pi}(s) = \\sum_{s'} P(s,\\pi(s),s')[ R(s,\\pi(s),s') + \\gamma V^{\\pi}(s')]$$\n",
    "\n",
    "You'll have to solve a linear system in your code. (Find an exact solution, e.g., with `np.linalg.solve`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EM9ubYfcJmKT"
   },
   "outputs": [],
   "source": [
    "def compute_vpi(mdp, policy, gamma):\n",
    "    \"\"\"\n",
    "    Computes V^pi(s) FOR ALL STATES under given policy.\n",
    "    :param policy: a dict of currently chosen actions {s : a}\n",
    "    :returns: a dict {state : V^pi(state) for all states}\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return < YOUR CODE >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rj-lYEYlJmKV"
   },
   "outputs": [],
   "source": [
    "test_policy = {s: np.random.choice(\n",
    "    mdp.get_possible_actions(s)) for s in mdp.get_all_states()}\n",
    "new_vpi = compute_vpi(mdp, test_policy, gamma)\n",
    "\n",
    "print(new_vpi)\n",
    "\n",
    "assert type(\n",
    "    new_vpi) is dict, \"compute_vpi must return a dict {state : V^pi(state) for all states}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N10D-AcjJmKY"
   },
   "source": [
    "Once we've got new state values, it's time to update our policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "baPpL7KwJmKY"
   },
   "outputs": [],
   "source": [
    "def compute_new_policy(mdp, vpi, gamma):\n",
    "    \"\"\"\n",
    "    Computes new policy as argmax of state values\n",
    "    :param vpi: a dict {state : V^pi(state) for all states}\n",
    "    :returns: a dict {state : optimal action for all states}\n",
    "    \"\"\"\n",
    "    <YOUR CODE >\n",
    "    return < YOUR CODE >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C679dWDdJmKa"
   },
   "outputs": [],
   "source": [
    "new_policy = compute_new_policy(mdp, new_vpi, gamma)\n",
    "\n",
    "print(new_policy)\n",
    "\n",
    "assert type(\n",
    "    new_policy) is dict, \"compute_new_policy must return a dict {state : optimal action for all states}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LdOD4h6wJmKc"
   },
   "source": [
    "__Main loop__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9v8KNo2EJmKc"
   },
   "outputs": [],
   "source": [
    "def policy_iteration(mdp, policy=None, gamma=0.9, num_iter=1000, min_difference=1e-5):\n",
    "    \"\"\" \n",
    "    Run the policy iteration loop for num_iter iterations or till difference between V(s) is below min_difference.\n",
    "    If policy is not given, initialize it at random.\n",
    "    \"\"\"\n",
    "    < A WHOLE LOT OF YOUR CODE >\n",
    "\n",
    "    return state_values, policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nbJetO-6JmKd"
   },
   "source": [
    "__Your PI Results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Smcfx9MrJmKe"
   },
   "outputs": [],
   "source": [
    "< Compare PI and VI on the MDP from bonus 1, then on small & large FrozenLake >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Va7mr35dJmKg"
   },
   "source": [
    "## Policy iteration convergence (3 pts)\n",
    "\n",
    "**Note:** Assume that $\\mathcal{S}, \\mathcal{A}$ are finite.\n",
    "\n",
    "We can define another Bellman operator:\n",
    "\n",
    "$$(T_{\\pi}V)(s) = \\mathbb{E}_{r, s'|s, a = \\pi(s)}\\left[r + \\gamma V(s')\\right]$$\n",
    "\n",
    "And rewrite policy iteration algorithm in operator form:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Initialize $\\pi_0$\n",
    "\n",
    "**for** $k = 0,1,2,...$ **do**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Solve $V_k = T_{\\pi_k}V_k$   \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Select $\\pi_{k+1}$ s.t. $T_{\\pi_{k+1}}V_k = TV_k$ \n",
    "\n",
    "**end for**\n",
    "\n",
    "---\n",
    "\n",
    "To prove convergence of the algorithm we need to prove two properties: contraction an monotonicity.\n",
    "\n",
    "#### Monotonicity (0.5 pts)\n",
    "\n",
    "For all $V, U$ if $V(s) \\le U(s)$   $\\forall s \\in \\mathcal{S}$ then $(T_\\pi V)(s) \\le (T_\\pi U)(s)$   $\\forall s \\in  \\mathcal{S}$\n",
    "\n",
    "*<-- Your proof here -->*\n",
    "\n",
    "#### Contraction (1 pts)\n",
    "\n",
    "$$\n",
    "||T_\\pi V - T_\\pi U||_{\\infty} \\le \\gamma ||V - U||_{\\infty}\n",
    "$$\n",
    "\n",
    "For all $V, U$\n",
    "\n",
    "*<-- Your proof here -->*\n",
    "\n",
    "#### Convergence (1.5 pts)\n",
    "\n",
    "Prove that there exists iteration $k_0$ such that $\\pi_k = \\pi^*$ for all $k \\ge k_0$\n",
    "\n",
    "*<-- Your proof here -->*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "seminar_vi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
